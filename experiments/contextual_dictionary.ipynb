{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4594a37f-3aaf-459b-b31c-502a4f44ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key is valid. Available models: ['whisper-1', 'dall-e-2', 'gpt-3.5-turbo-16k', 'tts-1-hd-1106', 'tts-1-hd', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-turbo', 'gpt-3.5-turbo-instruct-0914', 'gpt-3.5-turbo', 'gpt-3.5-turbo-instruct', 'text-embedding-3-small', 'tts-1', 'text-embedding-3-large', 'gpt-4-1106-preview', 'babbage-002', 'gpt-3.5-turbo-0125', 'tts-1-1106', 'gpt-4o-2024-05-13', 'dall-e-3', 'gpt-4-0613', 'gpt-4o', 'text-embedding-ada-002', 'gpt-4', 'davinci-002', 'gpt-3.5-turbo-1106']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "\n",
    "# For ChatGPT-4\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# alternatively set LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"\"  # \"true\"\n",
    "\n",
    "try:\n",
    "    models = openai.models.list()\n",
    "    print(\"API key is valid. Available models:\", [model.id for model in models.data])\n",
    "except openai.error.AuthenticationError as e:\n",
    "    print(\"API key is invalid:\", str(e))\n",
    "\n",
    "openai_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=os.getenv(\"OPENAI_API_KEY\"))  # gpt-4-turbo - more correct grammar info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db89eff5-e02d-467c-9f37-8906da6bf007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama3_request(prompt):\n",
    "    # This function should interact with your local Llama3 model.\n",
    "    # Replace the below code with actual API or command-line interaction.\n",
    "    import subprocess\n",
    "    result = subprocess.run(['ollama', 'run', 'llama3', '--prompt', prompt], capture_output=True, text=True)\n",
    "    return result.stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef5bf677-c750-40a3-a6ac-d3495f7abf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Prompt templates\n",
    "translation_system_template = \"\"\"Given the following text in {source_language}, \n",
    "translate the word marked as <b>{word}</b> from {source_language} to {target_language}. \n",
    "Give the meaning of it in the exact sentence.\n",
    "Put into result only word translation without surrounding <b></b>\"\"\"\n",
    "\n",
    "translation_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', translation_system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "translation_chain = translation_prompt_template | model | parser\n",
    "\n",
    "\n",
    "dictionary_system_template = \"\"\"Given the following text in {source_language}, \n",
    "write {source_language} - {target_language} dictionary article for the word marked as <b>{word}</b>.\n",
    "The article should be in {target_language}.\n",
    "Include grammar attributes - part of the speech, genre, number, countability and other grammar attributes.\n",
    "All grammar attributes should be on one line in a compact way like in good dictionaries.\n",
    "Include different meanings, declination table and other information you expect to see in a good dictionary like Oxford, but do not include examples.\n",
    "And do not include translation of the text provided.\n",
    "Give the result in HTML formatting, without any block marks.\"\"\"\n",
    "\n",
    "dictionary_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', dictionary_system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "dictionary_chain = dictionary_prompt_template | model | parser\n",
    "\n",
    "\n",
    "examples_system_template = \"\"\"Given the following text in {source_language}, \n",
    "provide at least seven examples in {source_language} of sentences using the word marked as <b>{word}</b> in his meaning in the sentence.\n",
    "Do not give as an example the usage in the given text.\n",
    "Give translations of the examples to {target_language}\n",
    "Each example in a separate paragraph (<p>).\n",
    "Give the result in HTML formatting, without any block marks.\n",
    "\"\"\"\n",
    "\n",
    "examples_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', examples_system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "examples_chain = examples_prompt_template | model | parser\n",
    "\n",
    "\n",
    "explanation_system_template = \"\"\"Given the following text in {source_language}, \n",
    "using only {source_language} explain the meaning of the word marked as <b>{word}</b> in exact sentence.\n",
    "You are a teacher who read the text with your student, use the exact context in the sentence for the explanation.\n",
    "\"\"\"\n",
    "\n",
    "explanation_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', explanation_system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "explanation_chain = explanation_prompt_template | model | parser\n",
    "\n",
    "\n",
    "# Function to interact with Llama3\n",
    "def llama3_chain(prompt_template, **kwargs):\n",
    "    prompt = prompt_template.format(**kwargs)\n",
    "    response = llama3_request(prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f95c324-b66c-4936-acda-7cecd7004623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation_examples_and_explanation(text: str, word: str, source_language: str, target_language: str, model: str = 'gpt'):\n",
    "    # Mark the specific word in the text\n",
    "    marked_text = text.replace(word, f\"<b>{word}</b>\", 1)\n",
    "    if model == 'gpt':\n",
    "        translation = translation_chain.invoke({\n",
    "            \"text\": marked_text, \"word\": word, \"source_language\": source_language, \"target_language\": target_language})\n",
    "        dictionary = dictionary_chain.invoke({\n",
    "            \"text\": marked_text, \"word\": word, \"source_language\": source_language, \"target_language\": target_language})\n",
    "        examples = examples_chain.invoke({\n",
    "            \"text\": marked_text, \"word\": word, \"source_language\": source_language, \"target_language\": target_language})\n",
    "        explanation = explanation_chain.invoke({\n",
    "            \"text\": marked_text, \"word\": word, \"source_language\": source_language, \"target_language\": target_language})\n",
    "    elif model == 'llama3':\n",
    "        translation = llama3_chain(translation_prompt_template, text=marked_text, word=word, source_language=source_language, target_language=target_language)\n",
    "        # examples = llama3_chain(example_prompt_template, text=marked_text, word=word, source_language=source_language, target_language=target_language)\n",
    "        # explanation = llama3_chain(explanation_prompt_template, text=marked_text, word=word, source_language=source_language)\n",
    "    return f\"{translation}<br><br>{dictionary}<br><br>{examples}<br><br>{explanation}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "38b2232f-0272-4621-bcc5-f9ffe75cc4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT-4 Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "leaf<br><br><p><b>list</b></p>\n",
       "<p><i>noun, masculine</i></p>\n",
       "<p><b>Meanings:</b></p>\n",
       "<ol>\n",
       "<li>leaf</li>\n",
       "<li>sheet (of paper)</li>\n",
       "</ol>\n",
       "<p><b>Declination:</b></p>\n",
       "<table>\n",
       "<tr><th>Case</th><th>Singular</th><th>Plural</th></tr>\n",
       "<tr><td>Nominative</td><td>list</td><td>listovi</td></tr>\n",
       "<tr><td>Genitive</td><td>lista</td><td>listova</td></tr>\n",
       "<tr><td>Dative</td><td>listu</td><td>listovima</td></tr>\n",
       "<tr><td>Accusative</td><td>list</td><td>listove</td></tr>\n",
       "<tr><td>Instrumental</td><td>listom</td><td>listovima</td></tr>\n",
       "<tr><td>Locative</td><td>listu</td><td>listovima</td></tr>\n",
       "<tr><td>Vocative</td><td>liste</td><td>listovi</td></tr>\n",
       "</table><br><br><p>Volim da šetam kroz šumu i posmatram svaki <b>list</b> na drveću. (I love to walk through the forest and observe every leaf on the trees.)</p>\n",
       "<p>Jesen je najlepše godišnje doba zbog šarenih <b>listova</b> koji padaju sa drveća. (Autumn is the most beautiful season because of the colorful leaves falling from the trees.)</p>\n",
       "<p>Na prozoru stoji vaza sa suvim <b>listovima</b> cveća. (There is a vase with dried flower petals on the window sill.)</p>\n",
       "<p>Uvek me oduševi kada vidim prvi zeleni <b>list</b> na granama u proleće. (I am always delighted when I see the first green leaf on the branches in spring.)</p>\n",
       "<p>Dok sam čistila dvorište, naletele su mi na oči neke osušene <b>listove</b>. (While I was cleaning the yard, some dried leaves caught my eye.)</p>\n",
       "<p>Deca su skupljala šarene <b>listiće</b> sa zemlje i pravila šarene buketiće. (The children were picking up colorful little leaves from the ground and making colorful bouquets.)</p>\n",
       "<p>Kada je vetar počeo da duva jače, svi <b>listovi</b> su počeli da se ljuljaju na granama. (When the wind started blowing stronger, all the leaves began to sway on the branches.)</p><br><br><b>List</b> u ovom kontekstu se odnosi na tanku, ravnu i obično široku strukturu koja se može naći na drveću ili papiru. U prvom delu rečenice, <b>list</b> sa drveta je pao na zemlju, što znači da je tanak deo drveta koji nosi lišće pao na zemlju. U drugom delu rečenice, na stolu je bio list papira sa važnim beleškama, reč je o tankom komadu papira gde su zapisane važne informacije."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "# serbian_text = \"Ljubav je najlepša stvar na svetu. Ljubav pokreće sve.\"\n",
    "# word_to_translate = \"Ljubav\"\n",
    "serbian_text = \"pokreće sve. list sa drveta je pao na zemlju. Na stolu je bio list papira sa važnim beleškama. Ljubav je najlepša \"\n",
    "word_to_translate = \"list\"\n",
    "source_language = \"Serbian\"\n",
    "target_language = \"English\"\n",
    "\n",
    "# Test with ChatGPT-4\n",
    "gpt = get_translation_examples_and_explanation(serbian_text, word_to_translate, source_language, target_language, model='gpt')\n",
    "\n",
    "# Test with Llama3\n",
    "# translation_llama, examples_llama, explanation_llama = get_translation_examples_and_explanation(serbian_text, word_to_translate, source_language, target_language, model='llama3')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "print(\"ChatGPT-4 Results:\")\n",
    "display(HTML(gpt))\n",
    "\n",
    "# print(\"Llama3 Results:\")\n",
    "# display(HTML(html_result_llama))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd8a80-9930-4157-bd89-c840c7007e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
