{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4594a37f-3aaf-459b-b31c-502a4f44ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key is valid. Available models: ['whisper-1', 'dall-e-2', 'gpt-3.5-turbo-16k', 'tts-1-hd-1106', 'tts-1-hd', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-turbo', 'gpt-3.5-turbo-instruct-0914', 'gpt-3.5-turbo', 'gpt-3.5-turbo-instruct', 'text-embedding-3-small', 'tts-1', 'text-embedding-3-large', 'gpt-4-1106-preview', 'babbage-002', 'gpt-3.5-turbo-0125', 'tts-1-1106', 'gpt-4o-2024-05-13', 'dall-e-3', 'gpt-4-0613', 'gpt-4o', 'text-embedding-ada-002', 'gpt-4', 'davinci-002', 'gpt-3.5-turbo-1106']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "\n",
    "# For ChatGPT-4\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# alternatively set LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"\"  # \"true\"\n",
    "\n",
    "try:\n",
    "    models = openai.models.list()\n",
    "    print(\"API key is valid. Available models:\", [model.id for model in models.data])\n",
    "except openai.error.AuthenticationError as e:\n",
    "    print(\"API key is invalid:\", str(e))\n",
    "\n",
    "openai_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=os.getenv(\"OPENAI_API_KEY\"))  # gpt-4-turbo - more correct grammar info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db89eff5-e02d-467c-9f37-8906da6bf007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama3_request(prompt):\n",
    "    # This function should interact with your local Llama3 model.\n",
    "    # Replace the below code with actual API or command-line interaction.\n",
    "    import subprocess\n",
    "    result = subprocess.run(['ollama', 'run', 'llama3', '--prompt', prompt], capture_output=True, text=True)\n",
    "    return result.stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0f95c324-b66c-4936-acda-7cecd7004623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import lru_cache\n",
    "from typing import Any, Dict\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "def _create_article_templates(self) -> Dict[str, Any]:\n",
    "        class SimpleOutputParser(BaseOutputParser[str]):\n",
    "            \"\"\"Simple output parser.\"\"\"\n",
    "\n",
    "            def parse(self, text: str) -> str:\n",
    "                return text\n",
    "\n",
    "        parser = SimpleOutputParser()\n",
    "\n",
    "        translation_system_template = \"\"\"Given the following text in {text_language},\n",
    "translate the term marked with <span class=\"highlighted-term\"> tag to {user_language}. \n",
    "Give translation of the term in the exact sentence where the term is (and not all occurrences in the text).\n",
    "Put into result only the term translation.\n",
    "If the text is not in {text_language}, prefix the result with the text language name in parentheses, like (Latin).\n",
    "\"\"\"\n",
    "\n",
    "        translation_prompt_template = ChatPromptTemplate.from_messages(\n",
    "            [(\"system\", translation_system_template), (\"user\", \"{text}\")]\n",
    "        )\n",
    "\n",
    "        dictionary_system_template = \"\"\"Given the term in {text_language},\n",
    "write {text_language} - {user_language} dictionary article for the term.\n",
    "The article should be in {user_language}.\n",
    "Include grammar attributes - part of the speech, genre, number, countability and other grammar attributes.\n",
    "All grammar attributes should be on one line in a compact way with abbreviations like in good dictionaries.\n",
    "Include different meanings, declination table and other information you expect to see in a good dictionary\n",
    "like Oxford, but do not include examples.\n",
    "If you are sure the text is in a different language, write the article based on that language and indicate\n",
    "it by starting the result with the detected language name in parentheses.\n",
    "Give the result in HTML formatting, without any block marks.\"\"\"\n",
    "\n",
    "        dictionary_prompt_template = ChatPromptTemplate.from_messages(\n",
    "            [(\"system\", dictionary_system_template), (\"user\", \"The term is: {term}\")]\n",
    "        )\n",
    "\n",
    "        examples_system_template = \"\"\"Given the term in {text_language}, \n",
    "provide up to seven examples in {text_language} of sentences with the term.\n",
    "After each example, provide the translation of the example to {user_language} in a separate paragraph \n",
    "using the <p> tag.\n",
    "Do not prefix the translation with ({user_language}) or with \"Translation.\" \n",
    "Separate examples with <hr> tags. \n",
    "Provide the result in HTML formatting, without any block marks.\n",
    "\n",
    "Ensure your response adheres strictly to these instructions:\n",
    "- Do not repeat examples.\n",
    "- If you detect a language different from {text_language}, mention that, \n",
    "but do not mention the language if it is {text_language}.\n",
    "- Do not mark the translation with \"Translation\" or similar terms.\n",
    "        \"\"\"\n",
    "\n",
    "        examples_prompt_template = ChatPromptTemplate.from_messages(\n",
    "            [(\"system\", examples_system_template), (\"user\", \"The term is: {term}\")]\n",
    "        )\n",
    "\n",
    "        explain_system_template = \"\"\"Explain using only {text_language}, the usage of the term marked\n",
    "in the text with a <span class=\"highlighted-term\"> tag.\n",
    "Explain the usage only in the sentence where the term is marked with the <span class=\"highlighted-term\"> tag, \n",
    "and not in other occurrences of the text.\n",
    "Only if the text is not in {text_language}, start with the detected language in parentheses.\n",
    "After <hr> provide the translation of the explanation to {user_language}.\n",
    "Give the result in HTML formatting without any additional block marks or labels.\n",
    "\n",
    "Ensure your response adheres strictly to these instructions:\n",
    "- Use {text_language} for the initial explanation.\n",
    "- Never put into the result names of the languages {text_language} or {user_language}.\n",
    "- Explain the exact sentence where the term is marked with the <span class=\"highlighted-term\"> tag.\n",
    "Do not mention usage of the term in sentences where it is not marked\n",
    "with the <span class=\"highlighted-term\"> tag.\n",
    "\"\"\"\n",
    "\n",
    "        explain_prompt_template = ChatPromptTemplate.from_messages(\n",
    "            [(\"system\", explain_system_template), (\"user\", \"{text}\")]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"Translate\": {\"template\": translation_prompt_template, \"parser\": parser},\n",
    "            \"Dictionary\": {\"template\": dictionary_prompt_template, \"parser\": parser},\n",
    "            \"Examples\": {\"template\": examples_prompt_template, \"parser\": parser},\n",
    "            \"Explain\": {\"template\": explain_prompt_template, \"parser\": parser},\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "38b2232f-0272-4621-bcc5-f9ffe75cc4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "leaf"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import types\n",
    "from IPython.display import display, HTML\n",
    "from lexiflux.llm import Llm\n",
    "\n",
    "# serbian_text = \"Ljubav je najlepša stvar na svetu. Ljubav pokreće sve.\"\n",
    "# word_to_translate = \"Ljubav\"\n",
    "\n",
    "Llm._create_article_templates = types.MethodType(_create_article_templates, Llm)\n",
    "llm = Llm()\n",
    "\n",
    "\n",
    "article_name = \"Translate\"\n",
    "article_params = {\n",
    "    \"model_name\": \"gpt-3.5-turbo\"  # \"gpt-4-turbo\"  # Specify the model to use\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"text\": 'pokreće sve. <span class=\"highlighted-term\">list</span> sa drveta je pao na zemlju. Na stolu je bio list papira sa važnim beleškama. Ljubav je najlepša',\n",
    "    \"term\": \"list\",\n",
    "    # \"text\": 'Abbati, medico, patronoque <span class=\"highlighted-term\">intima pande</span>.',\n",
    "    # \"term\": \"intima pande\",\n",
    "    \"text_language\": \"Serbian\",\n",
    "    \"user_language\": \"English\"\n",
    "}\n",
    "\n",
    "article = llm.get_article(article_name, article_params, data)\n",
    "display(HTML(article))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd8a80-9930-4157-bd89-c840c7007e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a2d19-7b56-4616-a88c-598e6a1d73c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047bcc1a-cbdd-43ae-a20a-550d256845bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
