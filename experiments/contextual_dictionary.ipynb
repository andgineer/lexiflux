{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4594a37f-3aaf-459b-b31c-502a4f44ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key is valid. Available models: ['whisper-1', 'dall-e-2', 'gpt-3.5-turbo-16k', 'tts-1-hd-1106', 'tts-1-hd', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-turbo', 'gpt-3.5-turbo-instruct-0914', 'gpt-3.5-turbo', 'gpt-3.5-turbo-instruct', 'text-embedding-3-small', 'tts-1', 'text-embedding-3-large', 'gpt-4-1106-preview', 'babbage-002', 'gpt-3.5-turbo-0125', 'tts-1-1106', 'gpt-4o-2024-05-13', 'dall-e-3', 'gpt-4-0613', 'gpt-4o', 'text-embedding-ada-002', 'gpt-4', 'davinci-002', 'gpt-3.5-turbo-1106']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "\n",
    "# For ChatGPT-4\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# alternatively set LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"\"  # \"true\"\n",
    "\n",
    "try:\n",
    "    models = openai.models.list()\n",
    "    print(\"API key is valid. Available models:\", [model.id for model in models.data])\n",
    "except openai.error.AuthenticationError as e:\n",
    "    print(\"API key is invalid:\", str(e))\n",
    "\n",
    "openai_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=os.getenv(\"OPENAI_API_KEY\"))  # gpt-4-turbo - more correct grammar info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db89eff5-e02d-467c-9f37-8906da6bf007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama3_request(prompt):\n",
    "    # This function should interact with your local Llama3 model.\n",
    "    # Replace the below code with actual API or command-line interaction.\n",
    "    import subprocess\n",
    "    result = subprocess.run(['ollama', 'run', 'llama3', '--prompt', prompt], capture_output=True, text=True)\n",
    "    return result.stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef5bf677-c750-40a3-a6ac-d3495f7abf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Prompt templates\n",
    "translation_system_template = \"\"\"Given the following text in {source_language}, \n",
    "translate the word marked as <b>{word}</b> from {source_language} to {target_language}. \n",
    "Give the meaning of it in the exact sentence.\n",
    "Put into result only word translation without surrounding <b></b>\"\"\"\n",
    "\n",
    "translation_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', translation_system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "translation_chain = translation_prompt_template | model | parser\n",
    "\n",
    "\n",
    "dictionary_system_template = \"\"\"Given the following text in {source_language}, \n",
    "write {source_language} - {target_language} dictionary article for the word marked as <b>{word}</b>.\n",
    "The article should be in {target_language}, describe part of the speach and other grammar attributes, declination table and other information \n",
    "you expect to see in a good dictionary. \n",
    "If they are different for different usage of the word give them for the usage in exact sentence.\n",
    "Give the result in HTML formatting, without any block marks.\"\"\"\n",
    "\n",
    "dictionary_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', dictionary_system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "dictionary_chain = dictionary_prompt_template | model | parser\n",
    "\n",
    "\n",
    "examples_system_template = \"\"\"Given the following text in {source_language}, \n",
    "provide three examples in {source_language} of sentences using the word marked as <b>{word}</b> in his meaning in the context.\"\"\"\n",
    "\n",
    "examples_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', examples_system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "examples_chain = examples_prompt_template | model | parser\n",
    "\n",
    "\n",
    "explanation_system_template = \"\"\"Given the following text in {source_language}, \n",
    "using only {source_language} explain the meaning of the word marked as <b>{word}</b> in exact sentence.\"\"\"\n",
    "\n",
    "explanation_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', explanation_system_template),\n",
    "    ('user', '{text}')\n",
    "])\n",
    "explanation_chain = explanation_prompt_template | model | parser\n",
    "\n",
    "\n",
    "# Function to interact with Llama3\n",
    "def llama3_chain(prompt_template, **kwargs):\n",
    "    prompt = prompt_template.format(**kwargs)\n",
    "    response = llama3_request(prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f95c324-b66c-4936-acda-7cecd7004623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation_examples_and_explanation(text: str, word: str, source_language: str, target_language: str, model: str = 'gpt'):\n",
    "    # Mark the specific word in the text\n",
    "    marked_text = text.replace(word, f\"<b>{word}</b>\", 1)\n",
    "    if model == 'gpt':\n",
    "        translation = translation_chain.invoke({\n",
    "            \"text\": marked_text, \"word\": word, \"source_language\": source_language, \"target_language\": target_language})\n",
    "        dictionary = dictionary_chain.invoke({\n",
    "            \"text\": marked_text, \"word\": word, \"source_language\": source_language, \"target_language\": target_language})\n",
    "        examples = examples_chain.invoke({\n",
    "            \"text\": marked_text, \"word\": word, \"source_language\": source_language, \"target_language\": target_language})\n",
    "        explanation = explanation_chain.invoke({\n",
    "            \"text\": marked_text, \"word\": word, \"source_language\": source_language, \"target_language\": target_language})\n",
    "    elif model == 'llama3':\n",
    "        translation = llama3_chain(translation_prompt_template, text=marked_text, word=word, source_language=source_language, target_language=target_language)\n",
    "        # examples = llama3_chain(example_prompt_template, text=marked_text, word=word, source_language=source_language, target_language=target_language)\n",
    "        # explanation = llama3_chain(explanation_prompt_template, text=marked_text, word=word, source_language=source_language)\n",
    "    return f\"{translation}<br><br>{dictionary}<br><br>{examples}<br><br>{explanation}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38b2232f-0272-4621-bcc5-f9ffe75cc4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT-4 Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "leaf<br><br><h2><b>list</b></h2>\n",
       "<p><i>Part of speech:</i> noun</p>\n",
       "<p><i>Plural form:</i> listovi</p>\n",
       "\n",
       "<p><b>1. </b> A leaf from a tree:</p>\n",
       "<ul>\n",
       "<li><b>Nominative:</b> list</li>\n",
       "<li><b>Genitive:</b> lista</li>\n",
       "<li><b>Dative:</b> listu</li>\n",
       "<li><b>Accusative:</b> list</li>\n",
       "<li><b>Instrumental:</b> listom</li>\n",
       "<li><b>Locative:</b> listu</li>\n",
       "</ul>\n",
       "\n",
       "<p><b>2. </b> A sheet of paper for writing:</p>\n",
       "<ul>\n",
       "<li><b>Nominative:</b> list</li>\n",
       "<li><b>Genitive:</b> lista</li>\n",
       "<li><b>Dative:</b> listu</li>\n",
       "<li><b>Accusative:</b> list</li>\n",
       "<li><b>Instrumental:</b> listom</li>\n",
       "<li><b>Locative:</b> listu</li>\n",
       "</ul><br><br>1. Prošetala je kroz šumu i primetila kako se <b>list</b> sa drveta lagano spuštao na tlo.\n",
       "2. U mojoj torbi uvek nosim blokčić sa <b>listovima</b> papira za brze beleške.\n",
       "3. Posle jake kiše, svi su se <b>listovi</b> na drveću sjajili na suncu.<br><br><b>List</b> je deo biljke koji obavlja funkciju fotosinteze i obično je tanak, zelen ili smeđ, sa karakterističnom nervaturom."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "# serbian_text = \"Ljubav je najlepša stvar na svetu. Ljubav pokreće sve.\"\n",
    "# word_to_translate = \"Ljubav\"\n",
    "serbian_text = \"pokreće sve. list sa drveta je pao na zemlju. Na stolu je bio list papira sa važnim beleškama. Ljubav je najlepša \"\n",
    "word_to_translate = \"list\"\n",
    "source_language = \"Serbian\"\n",
    "target_language = \"English\"\n",
    "\n",
    "# Test with ChatGPT-4\n",
    "gpt = get_translation_examples_and_explanation(serbian_text, word_to_translate, source_language, target_language, model='gpt')\n",
    "\n",
    "# Test with Llama3\n",
    "# translation_llama, examples_llama, explanation_llama = get_translation_examples_and_explanation(serbian_text, word_to_translate, source_language, target_language, model='llama3')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "print(\"ChatGPT-4 Results:\")\n",
    "display(HTML(gpt))\n",
    "\n",
    "# print(\"Llama3 Results:\")\n",
    "# display(HTML(html_result_llama))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd8a80-9930-4157-bd89-c840c7007e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
