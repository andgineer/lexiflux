# AI модели

Lexiflux использует AI модели для создания `Лексических статей` в `Боковой панели`
(вы можете открыть её с помощью синей иконки бинокля).

Также вы можете использовать AI для встроенного перевода текста. По умолчанию
используется Google Translate.

Чтобы настроить Боковую панель и встроенный перевод, смотрите [Языковые настройки](http://localhost:6100/language-preferences/).
Для каждого языка есть отдельные настройки, поэтому вы можете настроить
разные параметры для разных языков.

## Ollama
Вы можете [установить](docker.md#local-ollama-ai) в docker локальную AI модель [Ollama](https://github.com/jmorganca/ollama).

Она бесплатная, но требует около 6 ГБ оперативной памяти для работы. Помните, что это оперативная память для контейнера Docker, а не для хост-машины.

И она не очень точная.

## OpenAI (ChatGPT), Anthropic (Claude) и другие

Для использования коммерческих AI провайдеров вам нужен `API KEY`.

Смотрите раздел [Настройки AI](http://localhost:6100/ai-settings/), чтобы узнать, как получить ключ для разных AI провайдеров.