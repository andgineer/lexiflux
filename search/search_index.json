{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#lexiflux-reader","title":"Lexiflux reader","text":"<p>Master languages faster with our AI-powered reading companion.</p> <p>Instantly translate and understand foreign texts as you read, building your vocabulary and comprehension skills effortlessly.</p> <p></p> <p></p> <p>Eager to get started? Check out the Quick start guide.</p>"},{"location":"aimodels/","title":"AI Models","text":"<p>Lexiflux use AI models to create <code>AI Insights</code> in <code>Sidebar</code> (you open it with blue binocular icon).</p> <p>Also you can use AI for inline text translation. By default it uses Google Translate.</p> <p>To configure Sidebar and inline translation see Dictionary &amp; AI Insights Settings. There are separate settings for each language, so you can configure different settings for different languages.</p>"},{"location":"aimodels/#ai-insights-types","title":"AI Insights Types","text":""},{"location":"aimodels/#ai-powered-translate-lexical-origin-explain-sentence","title":"AI Powered (Translate, Lexical, Origin, Explain, Sentence)","text":"<p>They use predefined prompts to generate insights. You can select AI model (ChatGPT, Claude etc) to run them.</p>"},{"location":"aimodels/#custom-ai","title":"Custom AI","text":"<p>With type \"AI\" you can define your own prompt for AI model.</p>"},{"location":"aimodels/#dictionary","title":"Dictionary","text":"<p>There are a number of dictionaries embedded like Google Translate, Linguee Translator, MyMemory Translator, PONS Translator.</p>"},{"location":"aimodels/#site","title":"Site","text":"<p>You define what a URL to open and with which parameters. This is usefull for good translator that does not have API. Like glosbe.com.</p> <p>Most of them should be open in external window, but some of them even could be open inside the Sidebar.</p> <p>This is controlled by <code>open in new window</code> parameter.</p>"},{"location":"aimodels/#ai-models-openai-chatgpt-google-gemini-anthropic-claude-and-others","title":"AI models: OpenAI (ChatGPT), Google (Gemini), Anthropic (Claude) and others","text":"<p>To use commercial AI providers you need <code>API KEY</code>.</p> <p>See AI Connections section how to get one for different AI providers.</p> <p>Gemini 2.5 Flash is smart enough for even tricky language puzzles and can be used with free tier.</p>"},{"location":"aimodels/#ollama","title":"Ollama","text":"<p>You can install in the docker local AI Ollama model.</p> <p>It is free, but requires about 4G RAM to run. Remember this is RAM for the Docker container, not for the host machine.</p> <p>And it is not so smart as commercial models from OpenAI and Anthropic.</p>"},{"location":"docker/","title":"Lexiflux in Docker","text":""},{"location":"docker/#installation","title":"Installation","text":"<p>You always can use this magic command to start Lexiflux in Docker:</p> <pre><code>docker start lexiflux &gt; null 2&gt;&amp;1 || docker run -d -p 6100:8000 --name lexiflux andgineer/lexiflux\n</code></pre> <p>If you want to know details, read below. But you don't have to - the magic command above is all you need.</p>"},{"location":"docker/#starting-lexiflux-docker-container","title":"Starting Lexiflux Docker Container","text":"<p>First part of the command <code>docker start lexiflux</code> tries to start the container with the name <code>lexiflux</code>.</p> <p>In fact this is all that you need after initial container creation.</p>"},{"location":"docker/#creating-lexiflux-docker-container","title":"Creating Lexiflux Docker Container","text":"<p>If first part of the command fails, the second part of the command</p> <pre><code>docker run -d -p 6100:8000 --name lexiflux andgineer/lexiflux\n</code></pre> <p>downloads the image <code>andgineer/lexiflux</code> from the Docker Hub, creates a new container with the name <code>lexiflux</code> and exposes port <code>6100</code> on your host machine.</p>"},{"location":"docker/#local-ollama-ai","title":"Local Ollama AI","text":"<p>If you want to use free local AI, and have enough RAM, you can preload Ollama model in the docker.</p> <p>Add <code>OLLAMA_LOAD_MODEL=llama3.2</code> or whatever model you want to the <code>docker run</code> command.</p> <p>Please note it will download about 2Gb Ollama AI model and require about 4G RAM for the Docker container to run.</p>"},{"location":"docker/#configuration","title":"Configuration","text":""},{"location":"docker/#allowed-hosts","title":"Allowed Hosts","text":"<p>By default, the Docker container allows connections from any hostname (<code>*</code>). If you need to restrict access to specific hostnames, you can use the <code>LEXIFLUX_ALLOWED_HOSTS</code> environment variable:</p> <pre><code>docker run -d -p 6100:8000 -e LEXIFLUX_ALLOWED_HOSTS=\"localhost,example.com\" --name lexiflux andgineer/lexiflux\n</code></pre> <p>The value should be a comma-separated list of hostnames. This will replace the default <code>*</code> setting.</p>"},{"location":"docker/#stopping-lexiflux-docker-container","title":"Stopping Lexiflux Docker Container","text":"<p>To stop the container you can use</p> <pre><code>docker stop lexiflux\n</code></pre>"},{"location":"docker/#updates","title":"Updates","text":"<p>To update you can use</p> <pre><code>docker exec -it lexiflux ./manage update\ndocker restart lexiflux\n</code></pre> <p>But keep in mind that as with any update, it may break something. So it is better to make a backup before updating.</p>"},{"location":"docker/#backup","title":"Backup","text":"<p>To create archive with full backup of your Lexiflux Docker container.</p> Linux/macOSWindows (PowerShell) <p>Enter in the terminal:</p> <pre><code>docker commit lexiflux lexiflux_backup\ndocker save lexiflux_backup | gzip &gt; lexiflux_backup.tar.gz\n</code></pre> <p>In the command prompt, type:</p> <pre><code>docker commit lexiflux lexiflux_backup\ndocker save lexiflux_backup -o lexiflux_backup.tar\n</code></pre>"},{"location":"docker/#restore","title":"Restore","text":"<p>To delete current container and create new one from archive created on the Backup stage.</p> <p>Remember, you will lose all your data in the current container.</p> <p>Warning</p> <p>Again: all your books and reading progress in current container will be lost. We restore to the state that you saved on the Backup stage.</p> Linux/macOSWindows (PowerShell) <p>Enter in the terminal:</p> <pre><code>docker stop lexiflux\ndocker rm lexiflux\ngunzip -c lexiflux_backup.tar.gz | docker load\ndocker run -d -p 6100:8000 --name lexiflux lexiflux_backup\n</code></pre> <p>In the command prompt, type:</p> <pre><code>docker stop lexiflux\ndocker rm lexiflux\ndocker load -i lexiflux_backup.tar\ndocker run -d -p 6100:8000 --name lexiflux lexiflux_backup\n</code></pre>"},{"location":"quickstart/","title":"Quick start","text":"<p>You need to have Docker installed.</p> <p>Open the terminal and run the following command:</p> <pre><code>docker start lexiflux &gt; null 2&gt;&amp;1 || docker run -d -p 6100:8000 --name lexiflux andgineer/lexiflux\n</code></pre> <p>That's it! You have a running Lexiflux.</p> <p>Open it in web browser at http://localhost:6100</p> <p>Remember the DB with your books and reading progress is stored in the Docker container. If you remove the container, you will lose all your data.</p> <p>To backup your data, see the Backup section.</p> <p>To update to the latest version, see the Update section.</p>"}]}